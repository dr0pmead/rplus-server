using System.Text.Json;
using System.Text.RegularExpressions;
using Microsoft.EntityFrameworkCore;
using Pgvector;
using Pgvector.EntityFrameworkCore;
using RPlus.Hunter.API.Persistence;

namespace RPlus.Hunter.API.Services;

/// <summary>
/// The "Brain" of the AI recruiter.
/// Implements RAG (Retrieval Augmented Generation) + MCP Tools + DeepSeek R1 thought cleaning.
///
/// Architecture:
///   1. RAG: Embed user question â†’ cosine search company_knowledge â†’ inject facts into prompt
///   2. MCP Tools: Function calling for structured data extraction (salary, stack, experience)
///   3. Thought Cleaning: Strip DeepSeek R1 internal monologue (&lt;think&gt; tags) from response
///
/// Host: External GPU server (ai.rubikom.kz, RTX 5090)
/// Models: deepseek-r1:32b (reasoning), nomic-embed-text (embeddings)
/// </summary>
public sealed partial class AiBrainService
{
    private readonly IHttpClientFactory _httpFactory;
    private readonly IDbContextFactory<HunterDbContext> _dbFactory;
    private readonly IConfiguration _config;
    private readonly ILogger<AiBrainService> _logger;

    public AiBrainService(
        IHttpClientFactory httpFactory,
        IDbContextFactory<HunterDbContext> dbFactory,
        IConfiguration config,
        ILogger<AiBrainService> logger)
    {
        _httpFactory = httpFactory;
        _dbFactory = dbFactory;
        _config = config;
        _logger = logger;
    }

    /// <summary>
    /// Generates an AI response using RAG-augmented context and DeepSeek R1.
    /// </summary>
    /// <param name="profileId">Candidate profile ID (for logging).</param>
    /// <param name="conversationMessages">Full conversation history (system + user/assistant).</param>
    /// <returns>Clean AI response text (thought tags stripped).</returns>
    public async Task<string?> GenerateResponseAsync(
        Guid profileId,
        List<ConversationMessage> conversationMessages,
        CancellationToken ct = default)
    {
        var client = _httpFactory.CreateClient("RPlus.AI");
        var model = _config["AI:Model"] ?? "deepseek-r1:32b";
        var embedModel = _config["AI:EmbeddingModel"] ?? "nomic-embed-text";
        var contextSize = _config.GetValue("AI:ContextSize", 32768);
        var temperature = _config.GetValue("AI:Temperature", 0.6);
        var ragTopK = _config.GetValue("AI:RagTopK", 3);

        // Extract latest user message for RAG query
        var latestUserMessage = conversationMessages
            .LastOrDefault(m => m.Role == "user")?.Content ?? "";

        // â”€â”€ Step 1: RAG â€” Retrieval Augmented Generation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        var ragContext = await RetrieveRagContextAsync(
            client, embedModel, latestUserMessage, ragTopK, ct);

        // â”€â”€ Step 2: Build System Prompt with RAG facts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        var systemPrompt = BuildSystemPrompt(ragContext);

        // Replace system prompt in conversation if present, or prepend
        var messages = new List<object>();
        var hasSystem = false;

        foreach (var msg in conversationMessages)
        {
            if (msg.Role == "system")
            {
                messages.Add(new { role = "system", content = systemPrompt });
                hasSystem = true;
            }
            else
            {
                messages.Add(new { role = msg.Role, content = msg.Content });
            }
        }

        if (!hasSystem)
            messages.Insert(0, new { role = "system", content = systemPrompt });

        // NOTE: DeepSeek R1 does NOT support native tool/function calling.
        // MCP tools (save_candidate_fact) will be implemented via prompt engineering in v2.

        // â”€â”€ Step 3: AI Request â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        var payload = new
        {
            model,
            messages,
            stream = false,
            options = new { num_ctx = contextSize, temperature }
        };

        _logger.LogInformation(
            "Calling DeepSeek R1 for profile {ProfileId}, model={Model}, context={Context}",
            profileId, model, contextSize);

        var response = await client.PostAsJsonAsync("/api/chat", payload, ct);

        if (!response.IsSuccessStatusCode)
        {
            var errorBody = await response.Content.ReadAsStringAsync(ct);
            _logger.LogError("AI Brain returned {StatusCode}: {Body}",
                response.StatusCode, errorBody[..Math.Min(errorBody.Length, 200)]);
            return null;
        }

        var json = await response.Content.ReadFromJsonAsync<JsonElement>(ct);
        var content = json.GetProperty("message").GetProperty("content").GetString() ?? "";

        // â”€â”€ Step 4: Thought Cleaning (DeepSeek R1 Specific) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        var cleanResponse = CleanDeepSeekThoughts(content).Trim();

        _logger.LogInformation(
            "AI Brain response for profile {ProfileId}: {Response}",
            profileId, cleanResponse[..Math.Min(cleanResponse.Length, 100)]);

        return string.IsNullOrWhiteSpace(cleanResponse) ? null : cleanResponse;
    }

    // â”€â”€â”€ RAG Retrieval â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /// <summary>
    /// Embeds the user question and searches company_knowledge for relevant facts.
    /// Returns formatted context string or empty if no matches / RAG fails.
    /// </summary>
    private async Task<string> RetrieveRagContextAsync(
        HttpClient client,
        string embedModel,
        string query,
        int topK,
        CancellationToken ct)
    {
        if (string.IsNullOrWhiteSpace(query))
            return "";

        try
        {
            await using var db = await _dbFactory.CreateDbContextAsync(ct);

            // Check if we have any knowledge entries at all
            var hasKnowledge = await db.CompanyKnowledge.AnyAsync(ct);
            if (!hasKnowledge)
            {
                _logger.LogDebug("No company knowledge entries â€” RAG skipped");
                return "";
            }

            // Generate query embedding
            var vectorPayload = new { model = embedModel, prompt = query };
            var embedRes = await client.PostAsJsonAsync("/api/embeddings", vectorPayload, ct);

            if (!embedRes.IsSuccessStatusCode)
            {
                _logger.LogWarning("Embedding request failed: {Status}", embedRes.StatusCode);
                return "";
            }

            var embedJson = await embedRes.Content.ReadFromJsonAsync<JsonElement>(ct);
            var vectorData = embedJson.GetProperty("embedding").EnumerateArray()
                .Select(x => x.GetSingle()).ToArray();
            var vector = new Vector(vectorData);

            // Cosine similarity search â€” closest facts first
            var facts = await db.CompanyKnowledge
                .Where(k => k.Embedding != null)
                .OrderBy(k => k.Embedding!.CosineDistance(vector))
                .Take(topK)
                .Select(k => k.Content)
                .ToListAsync(ct);

            if (facts.Count == 0)
                return "";

            _logger.LogInformation("RAG retrieved {Count} facts for query: {Query}",
                facts.Count, query[..Math.Min(query.Length, 50)]);

            return string.Join("\n- ", facts);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "RAG retrieval failed, proceeding without context");
            return "";
        }
    }

    // â”€â”€â”€ System Prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    private static string BuildSystemPrompt(string ragContext)
    {
        var knowledgeSection = string.IsNullOrEmpty(ragContext)
            ? "ĞĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ñ„Ğ°ĞºÑ‚Ğ¾Ğ² Ğ² Ğ±Ğ°Ğ·Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹. Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ·Ğ½Ğ°ĞµÑˆÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚ â€” ÑĞºĞ°Ğ¶Ğ¸, Ñ‡Ñ‚Ğ¾ ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸ÑˆÑŒ Ñƒ ĞºĞ¾Ğ»Ğ»ĞµĞ³."
            : ragContext;

        return $"""
            Ğ¢Ğ«: ĞĞ»ĞµĞºÑĞ°Ğ½Ğ´Ñ€, Senior Talent Acquisition Partner ĞºĞ¾Ğ¼Ğ¿Ğ°Ğ½Ğ¸Ğ¸ RPlus.
            Ğ¦Ğ•Ğ›Ğ¬: Ğ˜Ğ½Ñ‚ĞµÑ€Ğ²ÑŒÑ Ñ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ğ¼ Ğ² WhatsApp.
            
            ğŸ§  Ğ‘ĞĞ—Ğ Ğ—ĞĞĞĞ˜Ğ™ (Ğ¤ĞĞšĞ¢Ğ« Ğ ĞšĞĞœĞŸĞĞĞ˜Ğ˜):
            {knowledgeSection}

            âš ï¸ Ğ˜ĞĞ¡Ğ¢Ğ Ğ£ĞšĞ¦Ğ˜Ğ˜:
            1. Ğ¢Ñ‹ â€” Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº. ĞÑ„Ğ¸Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾-Ğ´ĞµĞ»Ğ¾Ğ²Ğ¾Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ. ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾ Ğ½Ğ° "Ğ’Ñ‹".
            2. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾ (1-3 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ). ĞšĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚ Ñ‡Ğ¸Ñ‚Ğ°ĞµÑ‚ Ñ Ñ‚ĞµĞ»ĞµÑ„Ğ¾Ğ½Ğ°.
            3. Ğ•ÑĞ»Ğ¸ Ğ² Ğ‘Ğ°Ğ·Ğµ Ğ—Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ½ĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° â€” ÑĞºĞ°Ğ¶Ğ¸, Ñ‡Ñ‚Ğ¾ ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ñ‚Ğµ Ñƒ ĞºĞ¾Ğ»Ğ»ĞµĞ³.
            4. ĞĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Markdown (Ğ¶Ğ¸Ñ€Ğ½Ñ‹Ğ¹ ÑˆÑ€Ğ¸Ñ„Ñ‚, ÑĞ¿Ğ¸ÑĞºĞ¸, Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸).
            5. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ½Ğ° Ñ‚Ğ¾Ğ¼ Ğ¶Ğµ ÑĞ·Ñ‹ĞºĞµ, Ğ½Ğ° ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¼ Ğ¿Ğ¸ÑˆĞµÑ‚ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚.
            6. Ğ•ÑĞ»Ğ¸ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚ Ğ¿Ñ€Ğ¾ÑĞ²Ğ»ÑĞµÑ‚ Ğ¸Ğ½Ñ‚ĞµÑ€ĞµÑ â€” Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸ ÑƒĞ´Ğ¾Ğ±Ğ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ğ´Ğ»Ñ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ.
            7. Ğ•ÑĞ»Ğ¸ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚ Ğ¾Ñ‚ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ â€” Ğ¿Ğ¾Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ğ¸ Ğ·Ğ° ÑƒĞ´ĞµĞ»Ñ‘Ğ½Ğ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ.
            """;
    }

    // â”€â”€â”€ MCP Tools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    private static object[] BuildMcpTools()
    {
        return
        [
            new
            {
                type = "function",
                function = new
                {
                    name = "save_candidate_fact",
                    description = "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğ¹ Ñ„Ğ°ĞºÑ‚ Ğ¾ ĞºĞ°Ğ½Ğ´Ğ¸Ğ´Ğ°Ñ‚Ğµ (Ğ·Ğ°Ñ€Ğ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğµ Ğ¾Ğ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ñ, ÑÑ‚ĞµĞº, Ğ¾Ğ¿Ñ‹Ñ‚)",
                    parameters = new
                    {
                        type = "object",
                        properties = new
                        {
                            category = new
                            {
                                type = "string",
                                @enum = new[] { "salary", "stack", "experience", "availability", "location" }
                            },
                            value = new { type = "string", description = "Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ñ„Ğ°ĞºÑ‚Ğ°" }
                        },
                        required = new[] { "category", "value" }
                    }
                }
            }
        ];
    }

    /// <summary>
    /// Processes tool calls from the AI response (e.g., save_candidate_fact).
    /// </summary>
    private async Task ProcessToolCallsAsync(
        Guid profileId, JsonElement toolCalls, CancellationToken ct)
    {
        try
        {
            foreach (var call in toolCalls.EnumerateArray())
            {
                var funcName = call.GetProperty("function").GetProperty("name").GetString();
                var argsJson = call.GetProperty("function").GetProperty("arguments").GetString();

                if (funcName == "save_candidate_fact" && argsJson is not null)
                {
                    var args = JsonSerializer.Deserialize<JsonElement>(argsJson);
                    var category = args.GetProperty("category").GetString() ?? "unknown";
                    var value = args.GetProperty("value").GetString() ?? "";

                    _logger.LogInformation(
                        "MCP Tool: save_candidate_fact for profile {ProfileId}: {Category}={Value}",
                        profileId, category, value[..Math.Min(value.Length, 80)]);

                    // TODO: Persist to candidate_facts table when schema is ready
                }
            }
        }
        catch (Exception ex)
        {
            _logger.LogWarning(ex, "Tool call processing failed for profile {ProfileId}", profileId);
        }
    }

    // â”€â”€â”€ DeepSeek R1 Thought Cleaning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    /// <summary>
    /// Strips DeepSeek R1 internal monologue tags from response.
    /// DeepSeek R1 wraps its reasoning in &lt;think&gt;...&lt;/think&gt; blocks.
    /// Candidates must never see the AI's internal thoughts.
    /// </summary>
    private static string CleanDeepSeekThoughts(string input)
    {
        if (string.IsNullOrEmpty(input)) return input;
        return ThinkTagRegex().Replace(input, "");
    }

    [GeneratedRegex(@"<think>.*?</think>", RegexOptions.Singleline | RegexOptions.IgnoreCase)]
    private static partial Regex ThinkTagRegex();
}

/// <summary>
/// Simple conversation message DTO for AiBrainService.
/// </summary>
public sealed record ConversationMessage(string Role, string Content);
